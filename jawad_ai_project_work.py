# -*- coding: utf-8 -*-
"""Jawad_AI_PROJECT_work.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fUw6Ltv738Z6JnHp3i9fo1kxalVFTGVp
"""

"""AI Final Project
Automatically generated by Colaboratory.
Original file is located at
https://colab.research.google.com/drive/1fUw6Ltv738Z6JnHp3i9fo1kxalVFTGVp
#MY part Jawad 62846
"""
from google.colab import drive
# This will prompt for authorization.
drive.mount('/content/drive')

import pandas as pd
import re
import string
import nltk
import spacy
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, recall_score,precision_score
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import cross_val_score
from sklearn.metrics import plot_confusion_matrix

from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import MinMaxScaler
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.preprocessing import MinMaxScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn import metrics

from sklearn import model_selection, naive_bayes
from sklearn import tree
from sklearn.neighbors import KNeighborsClassifier

import pandas as pd
train_data = pd.read_csv('/content/drive/MyDrive/train.csv')
test_data = pd.read_csv('/content/drive/MyDrive/test.csv')

test_data.head(2)

train_data.head(2)

train = pd.DataFrame(train_data)

X = train.Slope
Y = train.Cover_Type
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2,random_state=109)
print("X_train : ",len(X_train))
print("X_test : ",len(X_test))
print("X_train : ",len(y_train))
print("X_test : ",len(y_test))


#Model 1

model1 = LogisticRegression()
T= X_train.values.reshape(-1,1)
model1.fit(T,y_train)
Test = X_test.values.reshape(-1,1)
predictions = model1.predict(Test)
accuracy_score(predictions,y_test)*100

#Model 2

model2 = RandomForestClassifier(n_estimators=40)
m= X_train.values.reshape(-1,1)
model2.fit(m,y_train)
test = X_test.values.reshape(-1,1)
prediction =  model2.predict(test)
confusion_matrix(y_test,prediction)
model.score(test,y_test)


#Model 3

model3 = MultinomialNB()
scaler = MinMaxScaler()
T= X_train.reshape(-1,1)
X_train = scaler.fit_transform(T)
Test = test_data.reshape(-1,1)
X_test = scaler.fit_transform(Test)
model3.fit(X_train,y_train)
labels = model3.predict(Test)
accuracy_score(labels,y_test)*100

#Model 04

model4 = DecisionTreeClassifier()
d= X_train.reshape(-1,1)
model4 = model4.fit(d,y_train)
t=X_test.reshape(-1,1)
y_pred = model4.predict(t)
accuracy_score(y_pred,y_test)*100

#Model05

model5 = KNeighborsClassifier(n_neighbors=5)
d= X_train.reshape(-1,1)
model5.fit(d,y_train)
t=X_test.reshape(-1,1)
predictions =  model2.predict(t)
confusion_matrix(predictions,y_test)
accuracy_score(y_pred,y_test)*100

#model 6
model6 = AdaBoostClassifier(n_estimators=100)
d= X_train.reshape(-1,1)
model6.fit(X_train,y_train)
t=X_test.reshape(-1,1)
predictions =  model6.predict(X_test)
confusion_matrix(predictions,y_test)

id = test_data["Id"]
Test = pd.DataFrame(id)
arr=[]
for row in id:
  arr.append(labels[row])
Test["Cover type"] = arr
Test.to_csv('Final.csv',index = False)